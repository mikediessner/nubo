{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Bayesian Gaussian process for Bayesian optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best at evaluation 33: \t Inputs: [0.4456 1.     0.1017 0.6031 0.9557 0.    ], \t Outputs: [-2.447]\n",
      "New best at evaluation 40: \t Inputs: [0.     0.0752 0.351  0.262  0.3207 0.7352], \t Outputs: [-2.5521]\n",
      "New best at evaluation 45: \t Inputs: [0.4422 0.9751 0.7018 0.508  0.0311 0.    ], \t Outputs: [-2.7326]\n",
      "New best at evaluation 49: \t Inputs: [0.1384 0.1482 0.4061 0.2193 0.2555 0.7053], \t Outputs: [-2.9284]\n",
      "New best at evaluation 59: \t Inputs: [0.1107 0.2156 0.4114 0.3149 0.297  0.7104], \t Outputs: [-3.0154]\n",
      "New best at evaluation 62: \t Inputs: [0.4298 0.8893 0.7379 0.6256 0.166  0.    ], \t Outputs: [-3.0193]\n",
      "New best at evaluation 66: \t Inputs: [0.1856 0.1646 0.4307 0.2932 0.3455 0.6639], \t Outputs: [-3.2274]\n",
      "Evaluation: 66 \t Solution: 3.2274\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nubo.acquisition import ExpectedImprovement, UpperConfidenceBound\n",
    "from nubo.models import GaussianProcess\n",
    "from nubo.optimisation import lbfgsb\n",
    "from nubo.test_functions import Hartmann6D\n",
    "from nubo.utils import gen_inputs\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.priors import UniformPrior\n",
    "from gpytorch.settings import fast_computations\n",
    "\n",
    "\n",
    "# test function\n",
    "func = Hartmann6D(minimise=False)\n",
    "dims = func.dims\n",
    "bounds = func.bounds\n",
    "\n",
    "# training data\n",
    "x_train = gen_inputs(num_points=dims*5,\n",
    "                          num_dims=dims,\n",
    "                          bounds=bounds,\n",
    "                          seed=1)\n",
    "y_train = func(x_train)\n",
    "\n",
    "# Bayesian optimisation loop\n",
    "iters = 40\n",
    "\n",
    "for iter in range(iters):\n",
    "    \n",
    "    # specify Gaussian process\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Positive())\n",
    "    gp = GaussianProcess(x_train, y_train, likelihood=likelihood)\n",
    "    gp.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "    gp.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    gp.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "    likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, gp)\n",
    "\n",
    "    # set up pyro model for sampling\n",
    "    def pyro_gp(x, y):\n",
    "        with fast_computations(False, False, False):\n",
    "            sampled_gp = gp.pyro_sample_from_prior()\n",
    "            output = sampled_gp.likelihood(sampled_gp(x))\n",
    "            pyro.sample(\"obs\", output, obs=y)\n",
    "        return y\n",
    "\n",
    "    # run MCMC\n",
    "    nuts_kernel = NUTS(pyro_gp)\n",
    "    mcmc_run = MCMC(nuts_kernel, num_samples=128, warmup_steps=128, disable_progbar=True)\n",
    "    mcmc_run.run(x_train, y_train)\n",
    "\n",
    "    # load MCMC samples into model\n",
    "    gp.pyro_load_from_samples(mcmc_run.get_samples())\n",
    "\n",
    "    # specify acquisition function\n",
    "    # acq = ExpectedImprovement(gp=gp, y_best=torch.max(y_train))\n",
    "    acq = UpperConfidenceBound(gp=gp, beta=1.96**2)\n",
    "\n",
    "    # optimise acquisition function\n",
    "    x_new, _ = lbfgsb(func=lambda x: sum(acq(x))/mcmc_run.num_samples, bounds=bounds, num_starts=5)\n",
    "\n",
    "    # evaluate new point\n",
    "    y_new = func(x_new)\n",
    "    \n",
    "    # add to data\n",
    "    x_train = torch.vstack((x_train, x_new))\n",
    "    y_train = torch.hstack((y_train, y_new))\n",
    "\n",
    "    # print new best\n",
    "    if y_new > torch.max(y_train[:-1]):\n",
    "        print(f\"New best at evaluation {len(y_train)}: \\t Inputs: {x_new.numpy().reshape(dims).round(4)}, \\t Outputs: {-y_new.numpy().round(4)}\")\n",
    "\n",
    "# results\n",
    "best_iter = int(torch.argmax(y_train))\n",
    "print(f\"Evaluation: {best_iter+1} \\t Solution: {float(y_train[best_iter]):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
